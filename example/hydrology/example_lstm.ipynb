{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Tutorial: **HydroDL LSTM**\n",
    "\n",
    "---\n",
    "\n",
    "This notebook is a faithful implementation of the original [HydroDL](https://github.com/mhpi/hydroDL) LSTM model developed by [Dapeng Feng et al. (2020)](https://doi.org/10.1029/2019WR026793), and demonstrates both training and forward simulation in δMG. A pre-trained model is provided for those who only wish to run the model forward.\n",
    "\n",
    "For explanation of model structure, methodologies, data, and performance metrics, please refer to Feng's publications [below](#publication). If you find this code is useful in your own work, please include the aforementioned citation.\n",
    "\n",
    "**Note**: If you are new to the δMG framework, we suggest first looking at our [δHBV 1.0 tutorial](./../hydrology/example_dhbv.ipynb).\n",
    "\n",
    "<br>\n",
    "\n",
    "### High vs. Low Flow Experts\n",
    "\n",
    "The HydroDL LSTM comes in two flavors of data processing: one intended to maximize low-flow performance, and one to maximize high-flow performance. By default, the [LSTM config](./../conf/config_lstm.yaml) is set to reproduce the high-flow expert. The differences, along with changes that must be made to the config, are as follows:\n",
    "\n",
    "1. **Low-Flow Expert**: Precipition model input and runoff target data are normalized by a log-Gaussian like $$v_{norm} = \\frac{1}{\\sigma} \\left(log\\left(\\sqrt{var + 0.1}\\right) - \\mu_v\\right),$$ and an RMSE loss function is used in training; in the config,\n",
    "    - `train -> loss_function -> name: RmseLoss`\n",
    "    - `model -> flow_regime: low`\n",
    "\n",
    "2. **High-Flow Expert (Default)**: All model input and target data get a Gaussian normalizeation and an NSE loss function is used in training; in the config,\n",
    "    - `train -> loss_function -> name: NseBatchLoss`\n",
    "    - `model -> flow_regime: high`\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "### Before Running:\n",
    "- **Environment**: See [setup.md](./../../docs/setup.md) for ENV setup. δMG must be installed to run this notebook.\n",
    "\n",
    "- **Model**: Download pretrained LSTM model weights from [AWS](https://mhpi-spatial.s3.us-east-2.amazonaws.com/mhpi-release/models/1-lstm_trained.zip). Then update the model config:\n",
    "\n",
    "    - In [config_lstm.yaml](./../conf/config_lstm.yaml), update `model_dir` with your path to the parent directory containing both trained model weights `cudnnlstmmodel_ep300.pt` **and** normalization file `normalization_statistics.json`.\n",
    "    - **Note**: make sure this path includes the last closing forward slash: e.g., `./your/path/to/model/`.\n",
    "\n",
    "- **Data**: Download the CAMELS data extraction from [AWS](https://mhpi-spatial.s3.us-east-2.amazonaws.com/mhpi-release/data/1-camels.zip). Then, update the data configs:\n",
    "\n",
    "    - In [camels_531.yaml](./../conf/observations/camels_531.yaml) and [camels_671.yaml](./../conf/observations/camels_671.yaml), update...\n",
    "        1. `data_path` with path to `camels_daymetv2`,\n",
    "        2. `gage_info` with path to `gage_id.npy`,\n",
    "        3. `subset_path` with path to `531sub_id.txt` (camels_531 only).\n",
    "\n",
    "    - The full 671-basin or 531-basin CAMELS datasets can be selected by setting `observations: camels_671` or `camels_531` in the model config, respectively.\n",
    "\n",
    "- **Hardware**: The HydroDL LSTM requires CUDA support only available with Nvidia GPUs. For those without access, T4 GPUs can be used when running this notebook with δMG on [Google Colab](https://colab.research.google.com/).\n",
    "\n",
    "<br>\n",
    "\n",
    "### Publications:\n",
    "\n",
    "*Dapeng Feng, Kathyrn Lawson, Chaopeng Shen. \"Mitigating prediction error of deep learning streamflow models in large data-sparse regions with ensemble modeling and soft data.\" Geophysical Research Letters (2021). https://doi.org/10.1029/2021GL092999.*\n",
    "\n",
    "*Dapeng Feng, Kuai Fang, Chaopeng Shen. \"Enhancing Streamflow Forecast and Extracting Insights Using Long-Short Term Memory Networks With Data Integration at Continental Scales.\" Water Resources Research (2020). https://doi.org/10.1029/2019WR026793.*\n",
    "\n",
    "<br>\n",
    "\n",
    "### Issues:\n",
    "For questions, concerns, bugs, etc., please reach out by posting an [issue](https://github.com/mhpi/generic_deltamodel/issues).\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 1. Forward LSTM\n",
    "\n",
    "After completing [these](#before-running) steps, forward the LSTM with the code block below.\n",
    "\n",
    "Note:\n",
    "- The settings defined in the config [config_lstm.yaml](./../conf/config_lstm.yaml) are set to replicate benchmark performance on 531 CAMELS basins.\n",
    "- While published results are an average of 6 models using different random seeds, we only use one model and seed here for demonstration.\n",
    "\n",
    "### 1.1 Demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('../../')\n",
    "\n",
    "from dmg import ModelHandler\n",
    "from dmg.core.utils import import_data_loader, print_config, set_randomseed\n",
    "from example import load_config\n",
    "\n",
    "# ------------------------------------------#\n",
    "# Define model settings here.\n",
    "CONFIG_PATH = '../example/conf/config_lstm.yaml'\n",
    "# ------------------------------------------#\n",
    "\n",
    "\n",
    "# 1. Load configuration dictionary of model parameters and options.\n",
    "config = load_config(CONFIG_PATH)\n",
    "config['mode'] = 'sim'\n",
    "print_config(config)\n",
    "\n",
    "# Set random seed for reproducibility.\n",
    "set_randomseed(config['seed'])\n",
    "\n",
    "# 2. Initialize the LSTM.\n",
    "model = ModelHandler(config, verbose=True)\n",
    "\n",
    "# 3. Load and initialize a dataset dictionary of normalized NN model inputs.\n",
    "data_loader_cls = import_data_loader(config['data_loader'])\n",
    "data_loader = data_loader_cls(config, test_split=True, overwrite=False)\n",
    "\n",
    "# 4. Forward the model to get the predictions.\n",
    "output = model(\n",
    "    data_loader.eval_dataset,\n",
    "    eval=True,\n",
    ")\n",
    "\n",
    "# Denormalize the runoff predictions.\n",
    "runoff = output['CudnnLstmModel']['runoff']\n",
    "\n",
    "runoff = data_loader.from_norm(\n",
    "    output['CudnnLstmModel']['runoff'].cpu().detach().numpy(),\n",
    "    vars='runoff',\n",
    ")\n",
    "\n",
    "print(\"-------------\\n\")\n",
    "print(\n",
    "    f\"Runoff predictions (mm/day) for {runoff.shape[0]} days and \"\n",
    "    f\"{runoff.shape[1]} basins ~ \\nShowing the first 5 days for \"\n",
    "    f\"first basin: \\n {runoff[:5, :1]}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Visualizing Model Predictions\n",
    "\n",
    "After running model inference we can, e.g., view the runoff hydrograph for one of the basins to see we are getting expected outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from dmg.core.data import txt_to_array\n",
    "from dmg.core.post import plot_hydrograph\n",
    "from dmg.core.utils import Dates\n",
    "\n",
    "# ------------------------------------------#\n",
    "# Choose a basin by USGS gage ID to plot.\n",
    "GAGE_ID = 1022500\n",
    "TARGET = 'runoff'\n",
    "\n",
    "# Resample to 3-day prediction. Options: 'D', 'W', 'M', 'Y'.\n",
    "RESAMPLE = '3D'\n",
    "\n",
    "# Set the paths to the gage ID lists...\n",
    "GAGE_ID_PATH = config['observations']['gage_info']  # ./gage_id.npy\n",
    "GAGE_ID_531_PATH = config['observations']['subset_path']  # ./531sub_id.txt\n",
    "# ------------------------------------------#\n",
    "\n",
    "\n",
    "# 1. Get the runoff predictions and daily timesteps of the prediction window.\n",
    "pred = output['CudnnLstmModel'][TARGET]\n",
    "timesteps = Dates(config['sim'], config['model']['rho']).batch_daily_time_range\n",
    "\n",
    "# Remove warm-up period to match model output (see Note above.)\n",
    "timesteps = timesteps[config['model']['warm_up'] :]\n",
    "\n",
    "\n",
    "# 2. Load the gage ID lists and get the basin index.\n",
    "gage_ids = np.load(GAGE_ID_PATH, allow_pickle=True)\n",
    "gage_ids_531 = txt_to_array(GAGE_ID_531_PATH)\n",
    "\n",
    "print(f\"First 20 available gage IDs: \\n {gage_ids[:20]} \\n\")\n",
    "print(f\"First 20 available gage IDs (531 subset): \\n {gage_ids_531[:20]} \\n\")\n",
    "\n",
    "if config['observations']['name'] == 'camels_671':\n",
    "    if GAGE_ID in gage_ids:\n",
    "        basin_idx = list(gage_ids).index(GAGE_ID)\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            f\"Basin with gage ID {GAGE_ID} not found in the CAMELS 671 dataset.\"\n",
    "        )\n",
    "\n",
    "elif config['observations']['name'] == 'camels_531':\n",
    "    if GAGE_ID in gage_ids_531:\n",
    "        basin_idx = list(gage_ids_531).index(GAGE_ID)\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            f\"Basin with gage ID {GAGE_ID} not found in the CAMELS 531 dataset.\"\n",
    "        )\n",
    "else:\n",
    "    raise ValueError(\n",
    "        f\"Observation data supported: 'camels_671' or 'camels_531'. Got: {config['observations']}\"\n",
    "    )\n",
    "\n",
    "\n",
    "# 3. Get the data for the chosen basin and plot.\n",
    "runoff_pred_basin = pred[:, basin_idx].squeeze()\n",
    "\n",
    "plot_hydrograph(\n",
    "    timesteps,\n",
    "    runoff_pred_basin,\n",
    "    resample=RESAMPLE,\n",
    "    title=f\"Hydrograph for Kerrs Creek (Lexington, VA; Gage {GAGE_ID})\",\n",
    "    ylabel='Runoff (mm/day)',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 2. Train the HydroDL LSTM\n",
    "\n",
    "After completing [these](#before-running) steps, train an LSTM with the code block below.\n",
    "\n",
    "**Note**\n",
    "- The settings defined in the config [config_lstm.yaml](./../conf/config_lstm.yaml) are set to replicate benchmark performance.\n",
    "- For model training, set `mode: train` in the config, or modify after config dict has been created (see below).\n",
    "- `./output/` directory will be generated to store experiment and model files. This location can be adjusted by changing the `output_dir` key in your config. \n",
    "    - If you have set `model_dir` in your config, model save files will be stored there.\n",
    "- Default settings with 300 epochs, batch size 100, and training window from 1 October 1999 to 30 September 2008 should use 3.3GB of vram. Expect training times of 25 minutes on Nvidia A100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('../../')\n",
    "\n",
    "from dmg import ModelHandler\n",
    "from dmg.core.utils import (\n",
    "    import_data_loader,\n",
    "    import_trainer,\n",
    "    print_config,\n",
    "    set_randomseed,\n",
    ")\n",
    "from example import load_config\n",
    "\n",
    "# ------------------------------------------#\n",
    "# Define model settings here.\n",
    "CONFIG_PATH = '../example/conf/config_lstm.yaml'\n",
    "# ------------------------------------------#\n",
    "\n",
    "\n",
    "# 1. Load configuration dictionary of model parameters and options.\n",
    "config = load_config(CONFIG_PATH)\n",
    "config['mode'] = 'train'\n",
    "print_config(config)\n",
    "\n",
    "# Set random seed for reproducibility.\n",
    "set_randomseed(config['seed'])\n",
    "\n",
    "# 2. Initialize the LSTM with a model handler.\n",
    "model = ModelHandler(config, verbose=True)\n",
    "\n",
    "# 3. Load and initialize a dataset dictionary of NN model inputs.\n",
    "data_loader_cls = import_data_loader(config['data_loader'])\n",
    "data_loader = data_loader_cls(config, test_split=True, overwrite=False)\n",
    "\n",
    "\n",
    "# 4. Initialize trainer to handle model training.\n",
    "trainer_cls = import_trainer(config['trainer'])\n",
    "trainer = trainer_cls(\n",
    "    config,\n",
    "    model,\n",
    "    train_dataset=data_loader.train_dataset,\n",
    ")\n",
    "\n",
    "# 5. Start model training.\n",
    "trainer.train()\n",
    "print(f\"Training complete. Model saved to \\n{config['model_path']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Evaluate Model Performance\n",
    "\n",
    "After completing the training in [Section 2](#2-train-the-hydrodl-lstm), or with the trained model provided, test the LSTM below on evaluation data.\n",
    "\n",
    "**Note**\n",
    "- For model evaluation, set `mode: test` in the config, or modify after config dict has been created (see below).\n",
    "- When evaluating provided models, confirm that `test.test_epoch` in the config corresponds the training epochs completed for the model you want to test (e.g., 300).\n",
    "- Default settings with batch size 15 and testing window from 1 October 1989 to 30 September 1999 should use 2.3GB of VRAM. Expect evalutation times of 5 seconds on Nvidia A100.\n",
    "\n",
    "### 3.1 Runoff Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('../../')\n",
    "\n",
    "from dmg import ModelHandler\n",
    "from dmg.core.utils import (\n",
    "    import_data_loader,\n",
    "    import_trainer,\n",
    "    print_config,\n",
    "    set_randomseed,\n",
    ")\n",
    "from example import load_config\n",
    "\n",
    "# ------------------------------------------#\n",
    "# Define model settings here.\n",
    "CONFIG_PATH = '../example/conf/config_lstm.yaml'\n",
    "# ------------------------------------------#\n",
    "\n",
    "\n",
    "# 1. Load configuration dictionary of model parameters and options.\n",
    "config = load_config(CONFIG_PATH)\n",
    "config['mode'] = 'test'\n",
    "print_config(config)\n",
    "\n",
    "set_randomseed(config['seed'])\n",
    "\n",
    "# 2. Initialize the differentiable HBV 1.1p model (LSTM + HBV 1.1p).\n",
    "model = ModelHandler(config, verbose=True)\n",
    "\n",
    "# 3. Load and initialize a dataset dictionary of NN and HBV model inputs.\n",
    "data_loader_cls = import_data_loader(config['data_loader'])\n",
    "data_loader = data_loader_cls(config, test_split=True, overwrite=False)\n",
    "\n",
    "# 4. Initialize trainer to handle model evaluation.\n",
    "trainer_cls = import_trainer(config['trainer'])\n",
    "trainer = trainer_cls(\n",
    "    config,\n",
    "    model,\n",
    "    eval_dataset=data_loader.eval_dataset,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "# 5. Start testing the model.\n",
    "print('Evaluating model...')\n",
    "trainer.evaluate()\n",
    "print(f\"Metrics and predictions saved to \\n{config['sim_dir']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Visualize Trained Model Performance\n",
    "\n",
    "Once the model has been evaluated, a new directory `sim/` will be created in your *output_dir* (default `./output/`). This path will be populated with...\n",
    "\n",
    "1. Predicted runoff (`runoff.npy`),\n",
    "\n",
    "2. Runoff observation data for comparison against model predictions (`runoff_obs.npy`).\n",
    "\n",
    "Your output directory will also be populated with files containing individual basin and basin-aggregated metrics...\n",
    "2. `metrics.json`, containing evaluation metrics accross the test time range for each gage in the dataset,\n",
    "\n",
    "3. `metrics_agg.json`, containing evaluation metrics aggregated across all sites (mean, median, standard deviation).\n",
    "\n",
    "We can use these outputs to visualize the LSTM's performance with a \n",
    "1. Cumulative distribution function (CDF) plot, \n",
    "\n",
    "2. CONUS map of gage locations and metric (e.g., NSE) performance.\n",
    "\n",
    "<br>\n",
    "\n",
    "But first, let's first check the (basin-)aggregated metrics for NSE, KGE, bias, RMSE, and, for both high/low flow regimes, RMSE and absolute percent bias..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from dmg.core.data import load_json\n",
    "from dmg.core.post import print_metrics\n",
    "\n",
    "\n",
    "print(f\"Evaluation output files: {config['output_dir']} \\n\")\n",
    "\n",
    "# 1. Load the basin-aggregated evaluation results.\n",
    "metrics_path = os.path.join(config['output_dir'], 'metrics_agg.json')\n",
    "metrics = load_json(metrics_path)\n",
    "print(f\"Available metrics: {metrics.keys()} \\n\")\n",
    "\n",
    "# 2. Print the evaluation results.\n",
    "metric_names = [\n",
    "    # Choose metrics to show.\n",
    "    'nse',\n",
    "    'kge',\n",
    "    'bias',\n",
    "    'rmse',\n",
    "    'rmse_low',\n",
    "    'rmse_high',\n",
    "    'flv_abs',\n",
    "    'fhv_abs',\n",
    "]\n",
    "print_metrics(metrics, metric_names, mode='median', precision=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 CDF Plot\n",
    "\n",
    "The cumulative distribution function (CDF) plot tells us what percentage (CDF on the y-axis) of basins performed at least better than a given metric on the evaluation data.\n",
    "\n",
    "An example is given below for NSE, but you can change to your preferred metric (see the output from the previous cell), but note some may require changing *xbounds* in `plot_cdf()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dmg.core.post import plot_cdf\n",
    "\n",
    "# ------------------------------------------#\n",
    "# Choose the metric to plot. (See available metrics printed above, or in the metrics_agg.json file).\n",
    "METRIC = 'nse'\n",
    "# ------------------------------------------#\n",
    "\n",
    "\n",
    "# 1. Load the evaluation metrics.\n",
    "metrics_path = os.path.join(config['output_dir'], 'metrics.json')\n",
    "metrics = load_json(metrics_path)\n",
    "\n",
    "# 2. Plot the CDF for NSE.\n",
    "plot_cdf(\n",
    "    metrics=[metrics],\n",
    "    metric_names=[METRIC],\n",
    "    model_labels=['LSTM'],\n",
    "    title=\"CDF of NSE for LSTM\",\n",
    "    xlabel=METRIC.capitalize(),\n",
    "    figsize=(8, 6),\n",
    "    xbounds=(0, 1),\n",
    "    ybounds=(0, 1),\n",
    "    show_arrow=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Spatial Plot\n",
    "\n",
    "This plot shows the locations of each basin in the evaluation data, color-coded by performance on a metric. Here we give a plot for NSE, but as before, this can be changed to your preference. (See above; for metrics not valued between 0 and 1, you will need to set `dynamic_colorbar=True` in `geoplot_single_metric` to ensure proper coding.)\n",
    "\n",
    "Note, you will need to add paths to the CAMELS shapefile, gage IDs, and 531-gage subset which can be found in the [CAMELS download](#before-running)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from dmg.core.data import txt_to_array\n",
    "from dmg.core.post import geoplot_single_metric\n",
    "\n",
    "# ------------------------------------------#\n",
    "# Choose the metric to plot. (See available metrics printed above, or in the metrics_agg.json file).\n",
    "METRIC = 'nse'\n",
    "\n",
    "# Set the paths to the gage id lists and shapefiles...\n",
    "GAGE_ID_PATH = config['observations']['gage_info']  # ./gage_id.npy\n",
    "GAGE_ID_531_PATH = config['observations']['subset_path']  # ./531sub_id.txt\n",
    "SHAPEFILE_PATH = './your/path/to/camels/loc/camels671.shp'\n",
    "# ------------------------------------------#\n",
    "\n",
    "\n",
    "# 1. Load gage ids + basin shapefile with geocoordinates (lat, long) for every gage.\n",
    "gage_ids = np.load(GAGE_ID_PATH, allow_pickle=True)\n",
    "gage_ids_531 = txt_to_array(GAGE_ID_531_PATH)\n",
    "coords = gpd.read_file(SHAPEFILE_PATH)\n",
    "\n",
    "# 2. Format geocoords for 531- and 671-basin CAMELS sets.\n",
    "coords_531 = coords[coords['gage_id'].isin(list(gage_ids_531))].copy()\n",
    "\n",
    "coords['gage_id'] = pd.Categorical(\n",
    "    coords['gage_id'], categories=list(gage_ids), ordered=True\n",
    ")\n",
    "coords_531['gage_id'] = pd.Categorical(\n",
    "    coords_531['gage_id'], categories=list(gage_ids_531), ordered=True\n",
    ")\n",
    "\n",
    "coords = coords.sort_values('gage_id')  # Sort to match order of metrics.\n",
    "basin_coords_531 = coords_531.sort_values('gage_id')\n",
    "\n",
    "# 3. Load the evaluation metrics.\n",
    "metrics_path = os.path.join(config['output_dir'], 'metrics.json')\n",
    "metrics = load_json(metrics_path)\n",
    "\n",
    "# 4. Add the evaluation metrics to the basin shapefile.\n",
    "if config['observations']['name'] == 'camels_671':\n",
    "    coords[METRIC] = metrics[METRIC]\n",
    "    full_data = coords\n",
    "elif config['observations']['name'] == 'camels_531':\n",
    "    coords_531[METRIC] = metrics[METRIC]\n",
    "    full_data = coords_531\n",
    "else:\n",
    "    raise ValueError(\n",
    "        f\"Observation data supported: 'camels_671' or 'camels_531'. Got: {config['observations']}\"\n",
    "    )\n",
    "\n",
    "# 5. Plot the evaluation results spatially.\n",
    "geoplot_single_metric(\n",
    "    full_data,\n",
    "    METRIC,\n",
    "    rf\"Spatial Map of {METRIC.upper()} for LSTM on CAMELS \"\n",
    "    f\"{config['observations']['name'].split('_')[-1]}\",\n",
    "    dynamic_colorbar=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "delphi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
