{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Tutorial: **HydroDL LSTM**\n",
    "\n",
    "---\n",
    "\n",
    "This notebook is a faithful implementation of the original [HydroDL](https://github.com/mhpi/hydroDL) LSTM model developed by [Dapeng Feng et al. (2020)](https://doi.org/10.1029/2019WR026793), and demonstrates both training and forward simulation in δMG. A pre-trained model is provided for those who only wish to run the model forward.\n",
    "\n",
    "For explanation of model structure, methodologies, data, and performance metrics, please refer to Feng's publications [below](#publication). If you find this code is useful in your own work, please include the aforementioned citation.\n",
    "\n",
    "**Note**: If you are new to the δMG framework, we suggest first looking at our [δHBV 1.0 tutorial](./../hydrology/example_dhbv.ipynb).\n",
    "\n",
    "<br>\n",
    "\n",
    "### Before Running:\n",
    "- **Environment**: See [setup.md](./../../docs/setup.md) for ENV setup. δMG must be installed to run this notebook.\n",
    "\n",
    "- **Model**: Download pretrained LSTM model weights from [AWS](https://mhpi-spatial.s3.us-east-2.amazonaws.com/mhpi-release/models/lstm_trained.zip). Then update the model config:\n",
    "\n",
    "    - In [`./generic_deltamodel/example/conf/config_lstm.yaml`](./../conf/config_lstm.yaml), update *model_dir* with your path to the parent directory containing both trained model weights `cudnnlstmmodel_ep300.pt` **and** normalization file `normalization_statistics.json`.\n",
    "    - **Note**: make sure this path includes the last closing forward slash: e.g., `./your/path/to/model/`.\n",
    "\n",
    "- **Data**: Download the CAMELS data extraction from [AWS](https://mhpi-spatial.s3.us-east-2.amazonaws.com/mhpi-release/camels/camels_data.zip). Then, update the data configs:\n",
    "\n",
    "    - In [`./generic_deltamodel/example/conf/observations/camels_531.yaml`](./../conf/observations/camels_531.yaml) and [`camels_671.yaml`](./../conf/observations/camels_671.yaml), update...\n",
    "        1. *data_path* with `camels_dataset` path,\n",
    "        2. *gage_info* with `gage_ids.npy` path,\n",
    "        3. *subset_path* with `531_subset.txt` path (camels_531 only).\n",
    "\n",
    "    - The full 671-basin or 531-basin CAMELS datasets can be selected by setting `observations: camels_671` or `camels_531` in the model config, respectively.\n",
    "\n",
    "- **Hardware**: The HydroDL LSTM requires CUDA support only available with Nvidia GPUs. For those without access, T4 GPUs can be used when running this notebook with δMG on [Google Colab](https://colab.research.google.com/).\n",
    "\n",
    "<br>\n",
    "\n",
    "### Publications:\n",
    "\n",
    "*Dapeng Feng, Kathyrn Lawson, Chaopeng Shen. \"Mitigating prediction error of deep learning streamflow models in large data-sparse regions with ensemble modeling and soft data.\" Geophysical Research Letters (2021). https://doi.org/10.1029/2021GL092999.*\n",
    "\n",
    "*Dapeng Feng, Kuai Fang, Chaopeng Shen. \"Enhancing Streamflow Forecast and Extracting Insights Using Long-Short Term Memory Networks With Data Integration at Continental Scales.\" Water Resources Research (2020). https://doi.org/10.1029/2019WR026793.*\n",
    "\n",
    "<br>\n",
    "\n",
    "### Issues:\n",
    "For questions, concerns, bugs, etc., please reach out by posting an [issue](https://github.com/mhpi/generic_deltamodel/issues).\n",
    "\n",
    "--\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 1. Forward LSTM\n",
    "\n",
    "After completing [these](#before-running) steps, forward the LSTM with the code block below.\n",
    "\n",
    "Note:\n",
    "- The settings defined in the config `./generic_deltamodel/example/conf/config_lstm.yaml` are set to replicate benchmark performance on 531 CAMELS basins.\n",
    "- While published results are an average of 6 models using different random seeds, we only use one model and seed here for demonstration.\n",
    "\n",
    "### 1.1 Demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('../../')\n",
    "\n",
    "from dmg import ModelHandler\n",
    "from dmg.core.utils import import_data_loader, print_config, set_randomseed\n",
    "from example.example_utils import load_config\n",
    "\n",
    "# ------------------------------------------#\n",
    "# Define model settings here.\n",
    "CONFIG_PATH = '../example/conf/config_lstm.yaml'\n",
    "# ------------------------------------------#\n",
    "\n",
    "\n",
    "# 1. Load configuration dictionary of model parameters and options.\n",
    "config = load_config(CONFIG_PATH)\n",
    "config['mode'] = 'sim'\n",
    "print_config(config)\n",
    "\n",
    "# Set random seed for reproducibility.\n",
    "set_randomseed(config['seed'])\n",
    "\n",
    "# 2. Initialize the LSTM.\n",
    "model = ModelHandler(config, verbose=True)\n",
    "\n",
    "# 3. Load and initialize a dataset dictionary of normalized NN model inputs.\n",
    "data_loader_cls = import_data_loader(config['data_loader'])\n",
    "data_loader = data_loader_cls(config, test_split=True, overwrite=False)\n",
    "\n",
    "# 4. Forward the model to get the predictions.\n",
    "output = model(\n",
    "    data_loader.eval_dataset,\n",
    "    eval=True,\n",
    ")\n",
    "\n",
    "# Denormalize the runoff predictions.\n",
    "runoff = output['CudnnLstmModel']['runoff']\n",
    "\n",
    "runoff = data_loader.from_norm(\n",
    "    output['CudnnLstmModel']['runoff'].cpu().detach().numpy(),\n",
    "    vars='runoff',\n",
    ")\n",
    "\n",
    "print(\"-------------\\n\")\n",
    "print(\n",
    "    f\"Streamflow predictions for {runoff.shape[0]} days and \"\n",
    "    f\"{runoff.shape[1]} basins ~ \\nShowing the first 5 days for \"\n",
    "    f\"first basin: \\n {runoff[:5, :1]}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Creating a Model\n",
    "For this example, we demonstrate how to setup an minimal LSTM example with DeltaModel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader._denormalize(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('../../')\n",
    "sys.path.append('../../deltaModel')  # Add the root directory of deltaModel\n",
    "\n",
    "from example.example_utils import load_config\n",
    "from deltaModel.models.neural_networks import CudnnLstmModel as LSTM\n",
    "from deltaModel.models.neural_networks import init_nn_model\n",
    "from deltaModel.core.data.dataset_loading import get_dataset_dict\n",
    "from deltaModel.models.differentiable_model import DeltaModel as dHBV\n",
    "from deltaModel.core.data import take_sample\n",
    "\n",
    "\n",
    "CONFIG_PATH = '../example/conf/config_lstm.yaml'\n",
    "\n",
    "\n",
    "# 1. Load configuration dictionary of model parameters and options.\n",
    "config = load_config(CONFIG_PATH)\n",
    "device = config['device']\n",
    "\n",
    "# 2. Setup a dataset dict of NN model inputs.\n",
    "# Take a sample to reduce size on GPU.\n",
    "dataset = get_dataset_dict(config, train=True)\n",
    "dataset_sample = take_sample(config, dataset, days=730, basins=100)\n",
    "\n",
    "nx = dataset_sample['x'].shape[-1]\n",
    "ny = dataset_sample['target'].shape[-1]\n",
    "hidden_size = config['nn_model']['hidden_size']\n",
    "dr = config['nn_model']['dr']\n",
    "\n",
    "\n",
    "# 3. Initialize an LSTM\n",
    "lstm = LSTM(nx=nx, ny=ny, hiddenSize=hidden_size, dr=dr)\n",
    "\n",
    "## From here, forward or train the lstm just as any torch.nn.Module model.\n",
    "\n",
    "# 5. For example, to forward:\n",
    "output = lstm.forward(dataset_sample)\n",
    "\n",
    "\n",
    "print(\n",
    "    f\"Streamflow predictions for {output['flow_sim'].shape[0]} days and {output['flow_sim'].shape[1]} basins: Showing the first 5 days for 5 basins \\n {output['flow_sim'][:3, :3]}\"\n",
    ")  # TODO: Add a visualization here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "delphi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
